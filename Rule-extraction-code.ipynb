{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final RuleFit rule extraction code with no feature duplications or redundant conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rulefit import RuleFit\n",
    "\n",
    "def simplify_rule(rule):\n",
    "    \"\"\"\n",
    "    Simplifies a rule string by removing logically redundant conditions\n",
    "    and ensuring the rule format is valid.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conditions = rule.split(\" & \")\n",
    "        parsed_conditions = []\n",
    "        for cond in conditions:\n",
    "            parts = cond.split()\n",
    "            if len(parts) < 3:\n",
    "                continue\n",
    "            feature, operator, value = parts[:3]\n",
    "            value = float(value)\n",
    "            parsed_conditions.append((feature, operator, value))\n",
    "\n",
    "        simplified_conditions = {}\n",
    "        for feature, operator, value in parsed_conditions:\n",
    "            if feature not in simplified_conditions:\n",
    "                simplified_conditions[feature] = (operator, value)\n",
    "            else:\n",
    "                current_operator, current_value = simplified_conditions[feature]\n",
    "                if operator == \">\" and value > current_value:\n",
    "                    simplified_conditions[feature] = (operator, value)\n",
    "                elif operator == \"<=\" and value < current_value:\n",
    "                    simplified_conditions[feature] = (operator, value)\n",
    "\n",
    "        return \" & \".join([f\"{feature} {operator} {value}\" for feature, (operator, value) in simplified_conditions.items()])\n",
    "    except Exception as e:\n",
    "        print(f\"Error simplifying rule: {rule}. Error: {e}\")\n",
    "        return rule\n",
    "\n",
    "# Load Data\n",
    "input_dir = r'E:\\Abroad period research\\new idea implementation codes\\Second part of the paper\\26 features results\\3 best features'\n",
    "train_df = pd.read_csv(os.path.join(input_dir, \"3_training_selected_features.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(input_dir, \"3_validation_selected_features.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(input_dir, \"3_testing_selected_features.csv\"))\n",
    "\n",
    "# Combine Training and Validation Data\n",
    "train_val_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "X_train_val = train_val_df.drop(columns=[\"label\"]).values\n",
    "y_train_val = train_val_df[\"label\"].values\n",
    "feature_names = train_val_df.columns[:-1].tolist()\n",
    "\n",
    "# Train RuleFit Model\n",
    "rulefit_model = RuleFit(tree_size=4, sample_fract=0.7, max_rules=200, random_state=42)\n",
    "rulefit_model.fit(X_train_val, y_train_val, feature_names=feature_names)\n",
    "\n",
    "# Extract Rules\n",
    "rules = rulefit_model.get_rules()\n",
    "rules = rules[rules.coef != 0]  # Filter rules with non-zero coefficients\n",
    "\n",
    "if rules.empty:\n",
    "    print(\"No rules were generated. Check your data or model configuration.\")\n",
    "else:\n",
    "    # Simplify Rules\n",
    "    rules[\"rule\"] = rules[\"rule\"].apply(simplify_rule)\n",
    "\n",
    "    # Get Unique Classes\n",
    "    unique_classes = sorted(set(y_train_val))\n",
    "\n",
    "    # Display and Save Rules\n",
    "    print(\"\\nSimplified Top Rules in If-Then Format for All Classes:\")\n",
    "    if_then_rules = []\n",
    "    \n",
    "    for label in unique_classes:\n",
    "        # Filter top rules for each class by importance scores and class association\n",
    "        class_rules = rules[rules.apply(lambda x: np.argmax(x['coef']) == label if isinstance(x['coef'], np.ndarray) else x['coef'] > 0, axis=1)]\n",
    "        class_rules = class_rules.sort_values(by=\"importance\", ascending=False).head(20)  # Top N rules per class\n",
    "\n",
    "        print(f\"\\nClass {label} Rules:\")\n",
    "        for _, row in class_rules.iterrows():\n",
    "            rule_str = f\"If ({row['rule']}) then Class = {label} (Importance: {row['importance']:.4f})\"\n",
    "            print(rule_str)\n",
    "            if_then_rules.append(rule_str)\n",
    "\n",
    "    # Save Rules to File\n",
    "    output_file_path = \"simplified_rulefit_top_if_then_rules_for_all_classes.txt\"\n",
    "    with open(output_file_path, 'w') as f:\n",
    "        for rule in if_then_rules:\n",
    "            f.write(rule + \"\\n\")\n",
    "    print(f\"\\nSimplified If-Then rules for all classes have been saved to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Decision Tree rule extraction code with no feature duplications or redundant conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define the directory containing the CSV files\n",
    "stat_feature_dir = r'E:\\Abroad period research\\new idea implementation codes\\Second part of the paper\\26 features results\\3 best features'\n",
    "\n",
    "# Load the CSV files\n",
    "train_df = pd.read_csv(os.path.join(stat_feature_dir, \"3_training_selected_features.csv\"))\n",
    "val_df = pd.read_csv(os.path.join(stat_feature_dir, \"3_validation_selected_features.csv\"))\n",
    "test_df = pd.read_csv(os.path.join(stat_feature_dir, \"3_testing_selected_features.csv\"))\n",
    "\n",
    "# Separate features and labels\n",
    "train_stat_features = train_df.drop(columns=['label']).values\n",
    "train_labels = train_df['label'].values\n",
    "\n",
    "val_stat_features = val_df.drop(columns=['label']).values\n",
    "val_labels = val_df['label'].values\n",
    "\n",
    "test_stat_features = test_df.drop(columns=['label']).values\n",
    "test_labels = test_df['label'].values\n",
    "\n",
    "# Combine training and validation data for final training\n",
    "combined_features = np.vstack([train_stat_features, val_stat_features])\n",
    "combined_labels = np.hstack([train_labels, val_labels])\n",
    "\n",
    "# Train Decision Tree Classifier with specified hyperparameters\n",
    "clf = DecisionTreeClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    max_depth=10,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=4,\n",
    "    random_state=0\n",
    ")\n",
    "clf.fit(combined_features, combined_labels)\n",
    "\n",
    "# Extract rules in the form of \"If ... then ...\" with importance\n",
    "feature_names = list(train_df.columns[:-1])\n",
    "rules = []\n",
    "\n",
    "def traverse_tree(tree, feature_names, feature_importances, node=0, conditions=\"\", path_importance=0):\n",
    "    \"\"\"\n",
    "    Recursively traverse the decision tree to extract rules and calculate their importance.\n",
    "    \"\"\"\n",
    "    # Check if this is a leaf node\n",
    "    if tree.children_left[node] == -1 and tree.children_right[node] == -1:\n",
    "        # Leaf node, output the class prediction and importance\n",
    "        class_value = np.argmax(tree.value[node][0])\n",
    "        rule_importance = path_importance\n",
    "        rule = f\"If ({conditions.rstrip(' & ')}) then Class = {class_value} (Importance: {rule_importance:.4f})\"\n",
    "        rules.append(rule)\n",
    "    else:\n",
    "        # Internal node, calculate feature importance for this path\n",
    "        feature_index = tree.feature[node]\n",
    "        threshold = tree.threshold[node]\n",
    "\n",
    "        # Avoid invalid indices\n",
    "        if feature_index >= 0:\n",
    "            # Update path importance using the feature importance of the current feature\n",
    "            path_importance += feature_importances[feature_index]\n",
    "\n",
    "            # Left child (feature <= threshold)\n",
    "            left_conditions = conditions + f\"{feature_names[feature_index]} <= {threshold:.3f} & \"\n",
    "            traverse_tree(tree, feature_names, feature_importances, tree.children_left[node], left_conditions, path_importance)\n",
    "\n",
    "            # Right child (feature > threshold)\n",
    "            right_conditions = conditions + f\"{feature_names[feature_index]} > {threshold:.3f} & \"\n",
    "            traverse_tree(tree, feature_names, feature_importances, tree.children_right[node], right_conditions, path_importance)\n",
    "\n",
    "# Traverse the tree to extract rules\n",
    "try:\n",
    "    traverse_tree(clf.tree_, feature_names, clf.feature_importances_)\n",
    "except Exception as e:\n",
    "    print(f\"Error during tree traversal: {e}\")\n",
    "\n",
    "# Simplify a single rule by merging redundant conditions\n",
    "def simplify_rule(rule):\n",
    "    conditions_part, result_part = rule.split(\") then\")\n",
    "    conditions = conditions_part.replace(\"If (\", \"\").split(\" & \")\n",
    "    simplified_conditions = {}\n",
    "\n",
    "    # Extract feature and threshold for each condition\n",
    "    for condition in conditions:\n",
    "        feature, operator, threshold = condition.split(\" \")\n",
    "        threshold = float(threshold)\n",
    "\n",
    "        # Simplify by keeping the most restrictive range\n",
    "        if feature not in simplified_conditions:\n",
    "            simplified_conditions[feature] = {\"<=\": float('inf'), \">\": float('-inf')}\n",
    "        if operator == \"<=\":\n",
    "            simplified_conditions[feature][\"<=\"] = min(simplified_conditions[feature][\"<=\"], threshold)\n",
    "        elif operator == \">\":\n",
    "            simplified_conditions[feature][\">\"] = max(simplified_conditions[feature][\">\"], threshold)\n",
    "\n",
    "    # Reconstruct simplified conditions\n",
    "    final_conditions = []\n",
    "    for feature, thresholds in simplified_conditions.items():\n",
    "        if thresholds[\">\"] != float('-inf'):\n",
    "            final_conditions.append(f\"{feature} > {thresholds['>']:.3f}\")\n",
    "        if thresholds[\"<=\"] != float('inf'):\n",
    "            final_conditions.append(f\"{feature} <= {thresholds['<=']:.3f}\")\n",
    "\n",
    "    return f\"If ({' & '.join(final_conditions)}) then{result_part}\"\n",
    "\n",
    "# Simplify all rules\n",
    "simplified_rules = [simplify_rule(rule) for rule in rules]\n",
    "\n",
    "# Extract importance scores from simplified rules and sort them in descending order\n",
    "def extract_importance(rule):\n",
    "    importance_start = rule.find(\"(Importance: \") + len(\"(Importance: \")\n",
    "    importance_end = rule.find(\")\", importance_start)\n",
    "    return float(rule[importance_start:importance_end])\n",
    "\n",
    "# Sort rules by importance in descending order\n",
    "sorted_rules = sorted(simplified_rules, key=extract_importance, reverse=True)\n",
    "\n",
    "# Display sorted and simplified rules\n",
    "print(\"Simplified and Sorted Rules:\")\n",
    "for rule in sorted_rules:\n",
    "    print(rule)\n",
    "\n",
    "# Save sorted and simplified rules to a file\n",
    "output_file_path = r'E:\\Abroad period research\\new idea implementation codes\\Second part of the paper\\26 features results\\3 best features\\simplified_sorted_rules.txt'\n",
    "with open(output_file_path, 'w') as f:\n",
    "    for rule in sorted_rules:\n",
    "        f.write(rule + \"\\n\")\n",
    "\n",
    "print(f\"Simplified and sorted rules have been saved to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
