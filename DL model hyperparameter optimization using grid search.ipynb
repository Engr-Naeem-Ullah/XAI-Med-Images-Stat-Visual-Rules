{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 280 validated image filenames belonging to 4 classes.\n",
      "Found 60 validated image filenames belonging to 4 classes.\n",
      "Found 60 validated image filenames belonging to 4 classes.\n",
      "Training with lr=0.001, epochs=10, batch_size=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.001, epochs=10, batch_size=32\n",
      "Validation accuracy: 0.4500\n",
      "Training with lr=0.001, epochs=10, batch_size=64\n",
      "Validation accuracy: 0.2333\n",
      "Training with lr=0.001, epochs=10, batch_size=128\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.001, epochs=30, batch_size=16\n",
      "Validation accuracy: 0.2500\n",
      "Training with lr=0.001, epochs=30, batch_size=32\n",
      "Validation accuracy: 0.4167\n",
      "Training with lr=0.001, epochs=30, batch_size=64\n",
      "Validation accuracy: 0.3833\n",
      "Training with lr=0.001, epochs=30, batch_size=128\n",
      "Validation accuracy: 0.4333\n",
      "Training with lr=0.001, epochs=50, batch_size=16\n",
      "Validation accuracy: 0.5000\n",
      "Training with lr=0.001, epochs=50, batch_size=32\n",
      "Validation accuracy: 0.4333\n",
      "Training with lr=0.001, epochs=50, batch_size=64\n",
      "Validation accuracy: 0.3667\n",
      "Training with lr=0.001, epochs=50, batch_size=128\n",
      "Validation accuracy: 0.5833\n",
      "Training with lr=0.005, epochs=10, batch_size=16\n",
      "Validation accuracy: 0.4833\n",
      "Training with lr=0.005, epochs=10, batch_size=32\n",
      "Validation accuracy: 0.3167\n",
      "Training with lr=0.005, epochs=10, batch_size=64\n",
      "Validation accuracy: 0.5500\n",
      "Training with lr=0.005, epochs=10, batch_size=128\n",
      "Validation accuracy: 0.4167\n",
      "Training with lr=0.005, epochs=30, batch_size=16\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.005, epochs=30, batch_size=32\n",
      "Validation accuracy: 0.4667\n",
      "Training with lr=0.005, epochs=30, batch_size=64\n",
      "Validation accuracy: 0.5833\n",
      "Training with lr=0.005, epochs=30, batch_size=128\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.005, epochs=50, batch_size=16\n",
      "Validation accuracy: 0.5833\n",
      "Training with lr=0.005, epochs=50, batch_size=32\n",
      "Validation accuracy: 0.4833\n",
      "Training with lr=0.005, epochs=50, batch_size=64\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.005, epochs=50, batch_size=128\n",
      "Validation accuracy: 0.4500\n",
      "Training with lr=0.01, epochs=10, batch_size=16\n",
      "Validation accuracy: 0.3833\n",
      "Training with lr=0.01, epochs=10, batch_size=32\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.01, epochs=10, batch_size=64\n",
      "Validation accuracy: 0.2167\n",
      "Training with lr=0.01, epochs=10, batch_size=128\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.01, epochs=30, batch_size=16\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.01, epochs=30, batch_size=32\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.01, epochs=30, batch_size=64\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.01, epochs=30, batch_size=128\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.01, epochs=50, batch_size=16\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.01, epochs=50, batch_size=32\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.01, epochs=50, batch_size=64\n",
      "Validation accuracy: 0.5833\n",
      "Training with lr=0.01, epochs=50, batch_size=128\n",
      "Validation accuracy: 0.1833\n",
      "Training with lr=0.02, epochs=10, batch_size=16\n",
      "Validation accuracy: 0.1833\n",
      "Training with lr=0.02, epochs=10, batch_size=32\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.02, epochs=10, batch_size=64\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.02, epochs=10, batch_size=128\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.02, epochs=30, batch_size=16\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.02, epochs=30, batch_size=32\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.02, epochs=30, batch_size=64\n",
      "Validation accuracy: 0.1833\n",
      "Training with lr=0.02, epochs=30, batch_size=128\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.02, epochs=50, batch_size=16\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.02, epochs=50, batch_size=32\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.02, epochs=50, batch_size=64\n",
      "Validation accuracy: 0.3000\n",
      "Training with lr=0.02, epochs=50, batch_size=128\n",
      "Validation accuracy: 0.3000\n",
      "Best Hyperparameters: {'learning_rate': 0.001, 'epochs': 50, 'batch_size': 128}\n",
      "Best Validation Accuracy: 0.5833\n",
      "Test Loss: 5.41531, Test Accuracy: 0.50\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load and preprocess dataset\n",
    "image_dir = Path(r'E:\\Abroad period research\\new idea implementation codes\\Second part of the paper\\26 features results\\small dataset for hyperparameter tunning')\n",
    "filepaths = list(image_dir.glob(r'**/*.png'))\n",
    "labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], filepaths))\n",
    "\n",
    "# Convert file paths and labels to a DataFrame\n",
    "filepaths = pd.Series(filepaths, name='Filepath').astype(str)\n",
    "labels = pd.Series(labels, name='Label')\n",
    "image_df = pd.concat([filepaths, labels], axis=1).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_df, temp_df = train_test_split(image_df, train_size=0.7, shuffle=True, random_state=1)\n",
    "val_df, test_df = train_test_split(temp_df, train_size=0.5, shuffle=True, random_state=1)\n",
    "\n",
    "# Create data generators\n",
    "def create_data_generators(train_df, val_df, test_df, batch_size):\n",
    "    train_gen = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input,\n",
    "        rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
    "        shear_range=0.2, zoom_range=0.2, horizontal_flip=True, fill_mode='nearest'\n",
    "    )\n",
    "    val_test_gen = ImageDataGenerator(\n",
    "        preprocessing_function=tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "    )\n",
    "\n",
    "    train_images = train_gen.flow_from_dataframe(train_df, x_col='Filepath', y_col='Label',\n",
    "                                                 target_size=(224, 224), color_mode='rgb', class_mode='categorical',\n",
    "                                                 batch_size=batch_size, shuffle=True, seed=0)\n",
    "    val_images = val_test_gen.flow_from_dataframe(val_df, x_col='Filepath', y_col='Label',\n",
    "                                                  target_size=(224, 224), color_mode='rgb', class_mode='categorical',\n",
    "                                                  batch_size=batch_size, shuffle=False)\n",
    "    test_images = val_test_gen.flow_from_dataframe(test_df, x_col='Filepath', y_col='Label',\n",
    "                                                   target_size=(224, 224), color_mode='rgb', class_mode='categorical',\n",
    "                                                   batch_size=batch_size, shuffle=False)\n",
    "    return train_images, val_images, test_images\n",
    "\n",
    "# Model-building function\n",
    "def build_model(learning_rate=0.001):\n",
    "    pretrained_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, pooling='avg', weights='imagenet')\n",
    "    pretrained_model.trainable = True\n",
    "    for layer in pretrained_model.layers[:-50]:  # Fine-tune last 50 layers\n",
    "        layer.trainable = False\n",
    "\n",
    "    model = tf.keras.Sequential([\n",
    "        pretrained_model,\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(len(train_df['Label'].unique()), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.005, 0.01, 0.02],\n",
    "    'epochs': [10, 30, 50],\n",
    "    'batch_size': [16, 32, 64, 128]\n",
    "}\n",
    "\n",
    "# Grid search\n",
    "best_accuracy = 0\n",
    "best_params = None\n",
    "train_images, val_images, test_images = create_data_generators(train_df, val_df, test_df, batch_size=32)\n",
    "\n",
    "for lr in param_grid['learning_rate']:\n",
    "    for epochs in param_grid['epochs']:\n",
    "        for batch_size in param_grid['batch_size']:\n",
    "            print(f\"Training with lr={lr}, epochs={epochs}, batch_size={batch_size}\")\n",
    "            model = build_model(learning_rate=lr)\n",
    "            history = model.fit(train_images, epochs=epochs, validation_data=val_images, batch_size=batch_size, verbose=0)\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            val_loss, val_accuracy = model.evaluate(val_images, verbose=0)\n",
    "            print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "            # Track best parameters\n",
    "            if val_accuracy > best_accuracy:\n",
    "                best_accuracy = val_accuracy\n",
    "                best_params = {'learning_rate': lr, 'epochs': epochs, 'batch_size': batch_size}\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Best Validation Accuracy: {best_accuracy:.4f}\")\n",
    "\n",
    "# Final evaluation on test set\n",
    "best_model = build_model(learning_rate=best_params['learning_rate'])\n",
    "best_model.fit(train_images, epochs=best_params['epochs'], batch_size=best_params['batch_size'], verbose=0)\n",
    "test_loss, test_acc = best_model.evaluate(test_images, verbose=0)\n",
    "print(f\"Test Loss: {test_loss:.5f}, Test Accuracy: {test_acc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
